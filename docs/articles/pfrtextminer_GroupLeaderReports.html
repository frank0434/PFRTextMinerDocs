<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>PFRTextMiner case study: GL reports • PFRTextMiner</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha256-916EbMg70RQy9LHiGkXzG8hSg9EdNy97GazNG/aiY1w=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script><!-- sticky kit --><script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="PFRTextMiner case study: GL reports">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">PFRTextMiner</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.2.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/pfrtextminer.html">PFRTextMiner: Webscraping and Text Mining at Plant &amp; Food Research</a>
    </li>
    <li>
      <a href="../articles/pfrtextminer_GroupLeaderReports.html">PFRTextMiner case study: GL reports</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/PlantandFoodResearch/PFRTextMiner">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><script src="pfrtextminer_GroupLeaderReports_files/jquery-1.11.3/jquery.min.js"></script><script src="pfrtextminer_GroupLeaderReports_files/elevate-section-attrs-2.0/elevate-section-attrs.js"></script><script src="pfrtextminer_GroupLeaderReports_files/kePrint-0.0.1/kePrint.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>PFRTextMiner case study: GL reports</h1>
                        <h4 class="author">Jian (AKA Frank) Liu</h4>
            
            <h4 class="date">2020-05-09</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/PlantandFoodResearch/PFRTextMiner/blob/master/vignettes/pfrtextminer_GroupLeaderReports.Rmd"><code>vignettes/pfrtextminer_GroupLeaderReports.Rmd</code></a></small>
      <div class="hidden name"><code>pfrtextminer_GroupLeaderReports.Rmd</code></div>

    </div>

    
    
<div id="scraping-files-from-an-iplant-webpage" class="section level2">
<h2 class="hasAnchor">
<a href="#scraping-files-from-an-iplant-webpage" class="anchor"></a>Scraping files from an iPlant webpage</h2>
<p>It is essential to stay within the network to get the web scraping working. VPN must be on if one wants to use the package offsite. To make the credentials a bit easier to manage, it could be useful to save password as a environment variable. Call <code><a href="https://usethis.r-lib.org/reference/edit.html">usethis::edit_r_environ()</a></code> in the console if one is not familiar with the moficiation of environment variables. Simply type <code>PASSWORD=*****</code> in the <code>.Renviron</code> file. The <code>*****</code> represents one’s unique password.</p>
<p>One has to provide an url that accessible by the authentication.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a><span class="co"># The url we want to download the files from.</span></span>
<span id="cb1-2"><a href="#cb1-2"></a>url &lt;-<span class="st"> "https://iplant.plantandfood.co.nz/Team/sp/DataSci/Administration/Forms/BoardReports.aspx"</span></span>
<span id="cb1-3"><a href="#cb1-3"></a></span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="co"># Use the function scrape_file to download the files from the iPlant page.</span></span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="kw"><a href="../reference/scrape_file.html">scrape_file</a></span>(url)</span></code></pre></div>
</div>
<div id="mining-the-text-from-one-or-multiple-files" class="section level2">
<h2 class="hasAnchor">
<a href="#mining-the-text-from-one-or-multiple-files" class="anchor"></a>Mining the text from one or multiple files</h2>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1"></a><span class="co"># Extract the text from the documents between the titles specified.</span></span>
<span id="cb2-2"><a href="#cb2-2"></a>text_df &lt;-<span class="st"> </span><span class="kw"><a href="../reference/mine_text.html">mine_text</a></span>(<span class="dt">type =</span> <span class="st">"docx"</span>, <span class="dt">path =</span> <span class="st">"./temp_folder"</span>, <span class="dt">from =</span> <span class="st">"Impact Highlight"</span>, </span>
<span id="cb2-3"><a href="#cb2-3"></a>    <span class="dt">to =</span> <span class="st">"Outputs"</span>)</span></code></pre></div>
<table class="table table">
<thead><tr>
<th style="text-align:left;">
text
</th>
<th style="text-align:left;">
source
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
<span style="     display: block; overflow: scroll; height: 5em; width: 30em;">New Data Science Group and new Data Applications team PFR’s success is based on good quality science that is produced as efficiently and effectively as possible. Data is the key component to this science – for most projects the rate limiting step is no longer collecting the information, rather the processing and analysis. To recognize the importance that efficient data management, processing, analysis and interpretations play, a new group Data Science has been formed, with Linley Jesson as group leader. This group will serve as a central point to improve the quality and efficiency of data processing and analysis throughout the company. The group consists of two teams: Biometrics (led by Ruth Butler) which will continue to play a key role in ensuring the quality of research through encouraging sound trial design, statistical analysis and interpretation of results; and a new team Data Applications (led by Peter Jaksons) to help develop analysis pipelines for new or “difficult” types of data, including machine learning, text and data mining and genomic prediction. To highlight the role that efficient data processing can help to improve our outputs, Data Application team members Linley Jesson and Peter Jaksons have been working with members of the Field Crops group, also in Sustainable Production (Edmar Teixiera, Ellen Hume, Jo Sharp) IKS’s Eric Burgueño and NCI’s Hymmi Kong to deploy the simulation tools APSIM Classic and APSIM Next Generation in High Performance Computing system in powerPlant. The project uses massive parallel computing to automate the generation of input files, run over 500,000 simulations instantly. This tool can simulate crop yield and other key agricultural system’s variables (e.g. water and nitrogen use) across multiple years (e.g. using historical climate or climate change scenarios) and locations (e.g. spatial simulations ranging from within-paddock precision agriculture applications to landscape scale assessments). The gains in performance means we were able to model climate change impacts on crop yields over large regions such as the Hawkes Bay, which is soon to be expanded for all arable land in New Zealand. Running such simulations on a single-core computer would have taken 408 days, as opposed to 1 day spread across over 1000 CPU cores in a high performance computing environment. To analyse and interpret the large number of APSIM output files user-friendly interactive visualization tools have been developed using R-shiny, including one by summer student Doney Zhang which maps the outcome of precision management applications to spatially variable enterprises. Other examples of data pipelines in which the new Data Applications team has already been instrumental in are genomic selection projects for both apples and kiwifruit. In these cases setting up workflows to combine data from various sources (genomic, phenotypic, pedigree) and being able to handle these large data sets improves both the reliability and quality of the research and at the same time reduces the time cost of these and future genomic selection projects. The data applications team will continue to help scientists to develop and increase efficiency for these sorts of pipelines, and improve the type of automated reporting to clients.</span>
</td>
<td style="text-align:left;">
Data_Science_Group_outputs_2018-02.docx
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style="     display: block; overflow: scroll; height: 5em; width: 30em;">“Small data, Big impact” In PFR, the majority of data sets collected are “small’, of a size that is easily stored within Excel. Thus, these small datasets remain the back-bone of research data collected by PFR, even with the rise of “big data”. Poor management of such small data results in a major a drain on resources: manipulation to enable analysis is time consuming and frequently error-prone, even to the point of making data unusable. At best, this is a waste of effort and at worst is a loss of potential impact or publications. Therefore, it is imperative for the quality of PFR’s science that we have processes in place to ensure the quality of “small data”, particularly that stored in Excel. To this end, the Data Management in Practice project (DMiP) was initiated in August 2016, and ran for 18 months. The project was supported by Blue Skies money, and the team comprised four biometricians, plus two scientists from outside the Data Science group. We developed several tools, ‘How-to’ documents and guidelines, which are available on the ‘Data Management’ iPlant site (Figure 1). Figure 1: Left: One of the Excel Templates produced by the DMiP team. Right: a page from the Data Management iPlant site. To introduce and advertise these materials, over the last 10 months we visited every PFR site in New Zealand bar the very smallest. We gave over 50 seminars/workshops, and over 300 people attended (Figure 2) - a marathon effort, but with a gratifying level of attendance, and lots of positive responses. Figure 2: Andrew McLachlan gives a DMiP seminar at Lincoln. 95250173990“They are easy to follow and to adapt to different situations. They provide a great base for keeping things organized and standardised, ideal for sharing data but also to simplify analyses”“We have used the template for all new projects since we completed the workshop. We can see the benefits of it and after the workshop feel confident using it”“Very well organised, the metadata pages are important and I wouldn’t otherwise include them”00“They are easy to follow and to adapt to different situations. They provide a great base for keeping things organized and standardised, ideal for sharing data but also to simplify analyses”“We have used the template for all new projects since we completed the workshop. We can see the benefits of it and after the workshop feel confident using it”“Very well organised, the metadata pages are important and I wouldn’t otherwise include them”Selected Comments on the Templates from the Feedback Survey: “They are easy to follow and to adapt to different situations. They provide a great base for keeping things organized and standardised, ideal for sharing data but also to simplify analyses” “We have used the template for all new projects since we completed the workshop. We can see the benefits of it and after the workshop feel confident using it” “Very well organised, the metadata pages are important and I wouldn’t otherwise include them” “They are easy to follow and to adapt to different situations. They provide a great base for keeping things organized and standardised, ideal for sharing data but also to simplify analyses” “We have used the template for all new projects since we completed the workshop. We can see the benefits of it and after the workshop feel confident using it” “Very well organised, the metadata pages are important and I wouldn’t otherwise include them” The feedback survey plus anecdotal evidence from Data Science group members suggests that the project has led to widespread improvements in the management of small data sets thus also improving the useability of data and efficiency of data management. However, the feedback also indicated that substantial follow up work – modifications to materials, more workshops, continuing reinforcement of ideas- is required. An approach to carry out this work will be devised in the next few months. The DMiP team (Ruth Butler, Linley Jesson, Andrew McLachlan, Duncan Hedderley, Melanie Davidson and Gareth Hill).</span>
</td>
<td style="text-align:left;">
Data_Science_Group_outputs_2018-06.docx
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style="     display: block; overflow: scroll; height: 5em; width: 30em;">The Data Science group is helping PFR to increase its efficiency in handling, managing and exploring data in many ways. To promote a culture of Data Science in the company the group hosted a Data Science Forum - “Everyone a Data Scientist”. Over 60 PFR staff attended the two-day event at Lincoln on September 5th and 6th. The meeting started with a discussion on leadership from Roger Robson-Williams about creating a Data Science culture in PFR. Guest speaker Kim Lung Chan, head of Data Science at the Callaghan Institute discussed opportunities for funding for students, research projects and businesses in Data Science and opportunities for increased collaboration between the two institutions. We then had a series of rapid fire talks with themes ranging from Data Management, Statistics, High Performance Computing and New Technologies. The second day ended with a discussion on “How to Solve Our Data Pain Points”. These “pain points” included increased automatic data handling and reporting, solutions for long-term data storage, and better data literacy among staff. Many of the solutions revolved around: building a strong and connected Data Science community that regularly engages in training, increasing the numbers of data literate staff, and the importance of metadata (data about data) and consistent formats and descriptors for understanding and sharing data. These discussions help promote a culture of data science at Plant and Food Research, so that our data is Findable, Accessible, Interoperable and Reusable (FAIR). In the long-term increased uptake of data science practices will enable more efficient data capture, handling and processing which can only boost productivity for PFR.</span>
</td>
<td style="text-align:left;">
Data_Science_Group_outputs_2018-09.docx
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style="     display: block; overflow: scroll; height: 5em; width: 30em;">The Science Data Facilitation Project is a collaborative project between Data Science and IKS aimed at promoting the best management of research data and ensuring data is Findable, Accessable, Interoperable and Reusable. Data Science member Carmel Woods is working with the Science Data Facilitator Melanie Burns to identify and train one staff member from each science team across the organisation in the role of Data Steward. These Data Stewards work with their teams to identify areas for improvement in data management practices, support the team to make this happen, and keep the momentum going. Currently there are 49 teams (out of 77, 64%) with a Data Steward and 35 (45%) have been trained. The Science Data Facilitation project is also collating the types of data that scientists are working with across the organisation, identifying individuals that want to be involved in discussions around good practice, and determining the best method to have these discussions and agree on good practice. The discussions have commenced with two data types (Genome Assembly and RNA Sequence) and documentation is almost complete. We will then seek feedback on the process and look at ways to improve the process when we select the next data type. This project is well on task to improve the culture of science data management within Plant and Food Research.</span>
</td>
<td style="text-align:left;">
Data_Science_Group_outputs_2018-11.docx
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style="     display: block; overflow: scroll; height: 5em; width: 30em;">Kate Richards in conjunction with Rolf Turner from Auckland University have been working on a paper to provide a statistical framework for data analysis methods that are used in problems that arise in quarantine research and address the problem of estimating lethal dose values in the context of fumigating export logs against several species of pine beetle. The approach is to make use of generalized linear mixed models on the basis of which we obtain interval estimates of a required lethal dose. They apply a “worst case scenario” paradigm in making a final choice of model. They first fit a wide range of models (determined by various choices of model characteristics). Then, after eliminating implausible values, find the maximum of the upper endpoints of the confidence intervals that were found. Then they take this maximum to be the (conservative) estimate of the required lethal dose. This framework was applied to a series of datasets exploring the dose of methyl bromide required to reach probit 9 level mortality. The current regulation for export of logs to china require a 16hr fumigation at a dose of 80-120g/m3 depending on temperature. Methyl bromide is a ozone depleting fumigant where the gas has to be recaptured. Using the framework described in the paper they were able to predict a lethal dose estimate 50% less than that currently required. This new dose of 40g/m3 is currently be tested in large scale at port trials. Plot of the “fit” of the chosen model. The blue dots are the observed (“raw”) success fractions. The red plus signs are the fitted success fractions with the (random) influence of the replicates included. The black line is the fitted success fraction formed using fixed effects only.</span>
</td>
<td style="text-align:left;">
Data_Science_Group_outputs_2019-02.docx
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style="     display: block; overflow: scroll; height: 5em; width: 30em;">Members of the Data Applications team have successfully applied computer vision algorithms to two problems: detecting and counting kiwifruit on the vine, and insects on sticky traps. These projects automate activities which are otherwise performed manually. This saves time and money, and allows larger quantities of data to be collected accurately. Interest in computer vision is increasing within PFR and from commercial partners such as Zespri and the seafood industry. Projects such as these help us build capabilities for PFR’s Growing Futures and Technology Development objectives. Fig. 1. Predicted assignment of A) insects on sticky-traps and B) kiwifruit on vines using machine-learning computer vision algorthms.</span>
</td>
<td style="text-align:left;">
Data_Science_Group_outputs_2019-06.docx
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style="     display: block; overflow: scroll; height: 5em; width: 30em;">We are investigating natural language processing techniques for extracting relationships from unstructured data. For example, analysing comments from sensory tests on kiwifruit cultivars to reveal underlying linkages between crop genotypes (e.g. Gold3) and their associated sensory terms (e.g. bitter, grainy, sweet, berry-like). This involves parsing the textual data into the form of a triple-store (subject-predicate-object), producing a constrained graph network, and then clustering the nodes in the network. Although this research is preliminary, initial prototypes are promising; an example from the 2019 Stage II Gold Kiwifruit testing is shown. Coupled with interactive visualisation platforms, this research will provide industry partners like Zespri with new and insightful knowledge about their sensory data. Further, it sets the foundations for including additional metadata, such as the chemical composition of a fruit or the genetic hierarchies between pedigrees. The hope is to connect various data types to obtain a deeper understanding of Plant &amp; Food Research’s crops. -636087278238Figure SEQ Figure * ARABIC 1: Example directed acyclic graph of sensory concepts.Figure SEQ Figure * ARABIC 1: Example directed acyclic graph of sensory concepts. Figure SEQ Figure * ARABIC 1: Example directed acyclic graph of sensory concepts. Figure SEQ Figure * ARABIC 1: Example directed acyclic graph of sensory concepts. -64075192900 -635245272046Figure SEQ Figure * ARABIC 2: Example directed acyclic graph of sensory concepts (zoomed).Figure SEQ Figure * ARABIC 2: Example directed acyclic graph of sensory concepts (zoomed).-64075327100 Figure SEQ Figure * ARABIC 2: Example directed acyclic graph of sensory concepts (zoomed). Figure SEQ Figure * ARABIC 2: Example directed acyclic graph of sensory concepts (zoomed).</span>
</td>
<td style="text-align:left;">
Data_Science_Group_outputs_2019-10.docx
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style="     display: block; overflow: scroll; height: 5em; width: 30em;">Give an example here of progress towards delivery of impact through a SIGNIFICANT science achievement. This is the major part of the report and should be a paragraph or two in length.</span>
</td>
<td style="text-align:left;">
Data_Science_Group_outputs_2020-Latest.docx
</td>
</tr>
</tbody>
</table>
</div>
<div id="summarising-text-into-most-important-sentences" class="section level2">
<h2 class="hasAnchor">
<a href="#summarising-text-into-most-important-sentences" class="anchor"></a>Summarising text into most important sentences</h2>
<p>Use for loop to exclude the document which has less than 3 sentences. It is an optional step. One could feed the document text directly to the <code>mine_summary</code> function. However, NAs will be returned if a document has less sentences than the input of <code>n_sentences</code> argument.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a><span class="co"># Apply the mine_summary function to each element of text in the dataframe.</span></span>
<span id="cb3-2"><a href="#cb3-2"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/nrow">nrow</a></span>(text_df)) {</span>
<span id="cb3-3"><a href="#cb3-3"></a>    <span class="cf">if</span> (<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/length">length</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/grep">gregexpr</a></span>(<span class="st">"[[:alnum:]][.!?]"</span>, text_df<span class="op">$</span>text[i])[[<span class="dv">1</span>]]) <span class="op">&lt;</span><span class="st"> </span><span class="dv">3</span>) {</span>
<span id="cb3-4"><a href="#cb3-4"></a>        text_df &lt;-<span class="st"> </span>text_df[<span class="op">-</span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(i), ]</span>
<span id="cb3-5"><a href="#cb3-5"></a>    }</span>
<span id="cb3-6"><a href="#cb3-6"></a>}</span>
<span id="cb3-7"><a href="#cb3-7"></a></span>
<span id="cb3-8"><a href="#cb3-8"></a>summaries &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/lapply">lapply</a></span>(text_df<span class="op">$</span>text, <span class="dt">FUN =</span> mine_summary, <span class="dt">n_sentences =</span> <span class="dv">3</span>)</span>
<span id="cb3-9"><a href="#cb3-9"></a><span class="co">#&gt; Parsing text into sentences and tokens...DONE</span></span>
<span id="cb3-10"><a href="#cb3-10"></a><span class="co">#&gt; Calculating pairwise sentence similarities...DONE</span></span>
<span id="cb3-11"><a href="#cb3-11"></a><span class="co">#&gt; Applying LexRank...DONE</span></span>
<span id="cb3-12"><a href="#cb3-12"></a><span class="co">#&gt; Formatting Output...DONE</span></span>
<span id="cb3-13"><a href="#cb3-13"></a><span class="co">#&gt; Parsing text into sentences and tokens...DONE</span></span>
<span id="cb3-14"><a href="#cb3-14"></a><span class="co">#&gt; Calculating pairwise sentence similarities...DONE</span></span>
<span id="cb3-15"><a href="#cb3-15"></a><span class="co">#&gt; Applying LexRank...DONE</span></span>
<span id="cb3-16"><a href="#cb3-16"></a><span class="co">#&gt; Formatting Output...DONE</span></span>
<span id="cb3-17"><a href="#cb3-17"></a><span class="co">#&gt; Parsing text into sentences and tokens...DONE</span></span>
<span id="cb3-18"><a href="#cb3-18"></a><span class="co">#&gt; Calculating pairwise sentence similarities...DONE</span></span>
<span id="cb3-19"><a href="#cb3-19"></a><span class="co">#&gt; Applying LexRank...DONE</span></span>
<span id="cb3-20"><a href="#cb3-20"></a><span class="co">#&gt; Formatting Output...DONE</span></span>
<span id="cb3-21"><a href="#cb3-21"></a><span class="co">#&gt; Parsing text into sentences and tokens...DONE</span></span>
<span id="cb3-22"><a href="#cb3-22"></a><span class="co">#&gt; Calculating pairwise sentence similarities...DONE</span></span>
<span id="cb3-23"><a href="#cb3-23"></a><span class="co">#&gt; Applying LexRank...DONE</span></span>
<span id="cb3-24"><a href="#cb3-24"></a><span class="co">#&gt; Formatting Output...DONE</span></span>
<span id="cb3-25"><a href="#cb3-25"></a><span class="co">#&gt; Parsing text into sentences and tokens...DONE</span></span>
<span id="cb3-26"><a href="#cb3-26"></a><span class="co">#&gt; Calculating pairwise sentence similarities...DONE</span></span>
<span id="cb3-27"><a href="#cb3-27"></a><span class="co">#&gt; Applying LexRank...DONE</span></span>
<span id="cb3-28"><a href="#cb3-28"></a><span class="co">#&gt; Formatting Output...DONE</span></span>
<span id="cb3-29"><a href="#cb3-29"></a><span class="co">#&gt; Parsing text into sentences and tokens...DONE</span></span>
<span id="cb3-30"><a href="#cb3-30"></a><span class="co">#&gt; Calculating pairwise sentence similarities...DONE</span></span>
<span id="cb3-31"><a href="#cb3-31"></a><span class="co">#&gt; Applying LexRank...DONE</span></span>
<span id="cb3-32"><a href="#cb3-32"></a><span class="co">#&gt; Formatting Output...DONE</span></span>
<span id="cb3-33"><a href="#cb3-33"></a><span class="co">#&gt; Parsing text into sentences and tokens...DONE</span></span>
<span id="cb3-34"><a href="#cb3-34"></a><span class="co">#&gt; Calculating pairwise sentence similarities...DONE</span></span>
<span id="cb3-35"><a href="#cb3-35"></a><span class="co">#&gt; Applying LexRank...DONE</span></span>
<span id="cb3-36"><a href="#cb3-36"></a><span class="co">#&gt; Formatting Output...DONE</span></span>
<span id="cb3-37"><a href="#cb3-37"></a><span class="co"># Append these summaries back to the original dataframe as a new column.</span></span>
<span id="cb3-38"><a href="#cb3-38"></a>text_df<span class="op">$</span>summary &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/lapply">sapply</a></span>(summaries, paste0)</span></code></pre></div>
<p>The <code>mine_summary</code> function will proceed if there are documents have less sentences than the threshold. But it will report a message. The return value will be <code>NA</code> in this case.</p>
</div>
<div id="extracting-the-most-frequent-keywords-from-the-text" class="section level2">
<h2 class="hasAnchor">
<a href="#extracting-the-most-frequent-keywords-from-the-text" class="anchor"></a>Extracting the most frequent keywords from the text</h2>
<div id="data-science-group-outputs-in--docx-format" class="section level3">
<h3 class="hasAnchor">
<a href="#data-science-group-outputs-in--docx-format" class="anchor"></a>Data science group outputs in <code>.docx</code> format</h3>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1"></a><span class="co"># Extract the n most frequent keywords from a text.</span></span>
<span id="cb4-2"><a href="#cb4-2"></a>keywords &lt;-<span class="st"> </span><span class="kw"><a href="../reference/mine_keywords.html">mine_keywords</a></span>(<span class="dt">text =</span> text_df<span class="op">$</span>text, <span class="dt">tag =</span> <span class="st">"NOUN"</span>, <span class="dt">barplot =</span> T, <span class="dt">wordcloud =</span> T, </span>
<span id="cb4-3"><a href="#cb4-3"></a>    <span class="dt">n_gram =</span> <span class="dv">2</span>)</span>
<span id="cb4-4"><a href="#cb4-4"></a>keywords</span>
<span id="cb4-5"><a href="#cb4-5"></a><span class="co">#&gt;                             keyword ngram freq</span></span>
<span id="cb4-6"><a href="#cb4-6"></a><span class="co">#&gt; 45                  data-management     2    8</span></span>
<span id="cb4-7"><a href="#cb4-7"></a><span class="co">#&gt; 46                     data-Science     2    8</span></span>
<span id="cb4-8"><a href="#cb4-8"></a><span class="co">#&gt; 47                     data-science     2    7</span></span>
<span id="cb4-9"><a href="#cb4-9"></a><span class="co">#&gt; 48                 data-application     2    6</span></span>
<span id="cb4-10"><a href="#cb4-10"></a><span class="co">#&gt; 49                 application-team     2    3</span></span>
<span id="cb4-11"><a href="#cb4-11"></a><span class="co">#&gt; 50                  computer-vision     2    3</span></span>
<span id="cb4-12"><a href="#cb4-12"></a><span class="co">#&gt; 51                    science-group     2    2</span></span>
<span id="cb4-13"><a href="#cb4-13"></a><span class="co">#&gt; 52                    Science-group     2    2</span></span>
<span id="cb4-14"><a href="#cb4-14"></a><span class="co">#&gt; 53                     science-data     2    2</span></span>
<span id="cb4-15"><a href="#cb4-15"></a><span class="co">#&gt; 54                     Science-data     2    2</span></span>
<span id="cb4-16"><a href="#cb4-16"></a><span class="co">#&gt; 55                       group-data     2    1</span></span>
<span id="cb4-17"><a href="#cb4-17"></a><span class="co">#&gt; 56                        team-data     2    1</span></span>
<span id="cb4-18"><a href="#cb4-18"></a><span class="co">#&gt; 57                      team-member     2    1</span></span>
<span id="cb4-19"><a href="#cb4-19"></a><span class="co">#&gt; 58                  change-scenario     2    1</span></span>
<span id="cb4-20"><a href="#cb4-20"></a><span class="co">#&gt; 59                      output-file     2    1</span></span>
<span id="cb4-21"><a href="#cb4-21"></a><span class="co">#&gt; 60             precision-management     2    1</span></span>
<span id="cb4-22"><a href="#cb4-22"></a><span class="co">#&gt; 61           management-application     2    1</span></span>
<span id="cb4-23"><a href="#cb4-23"></a><span class="co">#&gt; 62                     group-member     2    1</span></span>
<span id="cb4-24"><a href="#cb4-24"></a><span class="co">#&gt; 63                        data-pain     2    1</span></span>
<span id="cb4-25"><a href="#cb4-25"></a><span class="co">#&gt; 64                   science-member     2    1</span></span>
<span id="cb4-26"><a href="#cb4-26"></a><span class="co">#&gt; 65                     staff-member     2    1</span></span>
<span id="cb4-27"><a href="#cb4-27"></a><span class="co">#&gt; 66                     science-team     2    1</span></span>
<span id="cb4-28"><a href="#cb4-28"></a><span class="co">#&gt; 67            data-application-team     3    3</span></span>
<span id="cb4-29"><a href="#cb4-29"></a><span class="co">#&gt; 68               data-science-group     3    2</span></span>
<span id="cb4-30"><a href="#cb4-30"></a><span class="co">#&gt; 69               data-Science-group     3    2</span></span>
<span id="cb4-31"><a href="#cb4-31"></a><span class="co">#&gt; 70               group-data-science     3    1</span></span>
<span id="cb4-32"><a href="#cb4-32"></a><span class="co">#&gt; 71            team-data-application     3    1</span></span>
<span id="cb4-33"><a href="#cb4-33"></a><span class="co">#&gt; 72          application-team-member     3    1</span></span>
<span id="cb4-34"><a href="#cb4-34"></a><span class="co">#&gt; 73 precision-management-application     3    1</span></span>
<span id="cb4-35"><a href="#cb4-35"></a><span class="co">#&gt; 74             Science-group-member     3    1</span></span></code></pre></div>
</div>
<div id="science-group-leader-reports-in--pdf-format" class="section level3">
<h3 class="hasAnchor">
<a href="#science-group-leader-reports-in--pdf-format" class="anchor"></a>Science Group Leader reports in <code>.pdf</code> format</h3>
<p>It can take fair amount of time to run the pairwise sentence similarities for the whole document. For example, it took 11 minutes or so to process 8 pdf documents in on the windowns laptop.</p>
<p>Submitting a job via bsub will be a good option if one doesn’t like the job occupy the rstudio session.<br>
A brief workflow: - Prepare a R script that has the desired analysis process<br>
- Set up the environment variables to be available for R and bash<br>
- Have a think on the directory structure. e.g. where to store scraping data, where to output analysis results</p>
<p>Below is an example of submitting a text mining job to the server via bash.</p>
<div id="environment-prerequisite" class="section level4">
<h4 class="hasAnchor">
<a href="#environment-prerequisite" class="anchor"></a>Environment prerequisite</h4>
<p>There are depended packages that are only avaiable in certain R version, such as lexRankr. Therefore, it is important to source the right version of R from the global environment in powerplant.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1"></a><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/Sys.setenv">Sys.setenv</a></span>(<span class="dt">R_version =</span> <span class="st">"3.6.1"</span>)</span>
<span id="cb5-2"><a href="#cb5-2"></a><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/Sys.setenv">Sys.setenv</a></span>(<span class="dt">workingDir =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/file.path">file.path</a></span>(<span class="st">"/powerplant/workspace"</span>, <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/Sys.getenv">Sys.getenv</a></span>(<span class="st">"USER"</span>)))</span>
<span id="cb5-3"><a href="#cb5-3"></a><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/Sys.setenv">Sys.setenv</a></span>(<span class="dt">inputData =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/file.path">file.path</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/Sys.getenv">Sys.getenv</a></span>(<span class="st">"workingDir"</span>), <span class="st">"rawData"</span>, <span class="st">"inputData"</span>))</span>
<span id="cb5-4"><a href="#cb5-4"></a><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/Sys.setenv">Sys.setenv</a></span>(<span class="dt">intermediateData =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/file.path">file.path</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/Sys.getenv">Sys.getenv</a></span>(<span class="st">"workingDir"</span>), <span class="st">"intermediateData"</span>))</span>
<span id="cb5-5"><a href="#cb5-5"></a><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/Sys.setenv">Sys.setenv</a></span>(<span class="dt">outputData =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/file.path">file.path</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/Sys.getenv">Sys.getenv</a></span>(<span class="st">"workingDir"</span>), <span class="st">"outputData"</span>))</span></code></pre></div>
<p>Load tools</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1"></a><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/library">library</a></span>(RLinuxModules)</span>
<span id="cb6-2"><a href="#cb6-2"></a><span class="kw">module</span>(<span class="st">"load openlava/3.2"</span>)</span>
<span id="cb6-3"><a href="#cb6-3"></a><span class="kw">module</span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/paste">paste0</a></span>(<span class="st">"load R/"</span>, <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/Sys.getenv">Sys.getenv</a></span>(<span class="st">"R_version"</span>)))</span></code></pre></div>
<p>Check if tools are loaded sucessfully.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1"></a><span class="fu">which</span> bsub</span>
<span id="cb7-2"><a href="#cb7-2"></a><span class="fu">which</span> Rscript</span></code></pre></div>
</div>
<div id="prepare-an-analysis-recipe-for-a-desired-purpose" class="section level4">
<h4 class="hasAnchor">
<a href="#prepare-an-analysis-recipe-for-a-desired-purpose" class="anchor"></a>Prepare an analysis “recipe” for a desired purpose</h4>
<p>Here uses a duplicated script used in the above example for simiplcity. Copy the code into a new R script.</p>
<pre><code>#!/usr/bin/env Rscript

# Assume the library has been installed in the home direcotry.
library(PFRTextMiner, lib.loc = .libPaths()[1])

t1 &lt;- Sys.time()
text_df &lt;- mine_text(type = "pdf", path = Sys.getenv("inputData"))
# Apply the mine_summary function to each element of text in the dataframe.
for (i in 1:nrow(text_df)) {
  if (length(gregexpr('[[:alnum:]][.!?]', text_df$text[1])[[1]]) &lt; 3) {
    text_df &lt;- text_df[-c(i),]
  }
}

summaries &lt;- lapply(text_df$text, FUN = mine_summary, n_sentences = 3)

# Append these summaries back to the original dataframe as a new column.
text_df$summary &lt;- sapply(summaries, paste0)
keywords &lt;- mine_keywords(text = text_df$text, tag = "NOUN", n_gram = 2)
saveRDS(keywords, file.path(Sys.getenv("intermediateData"), "keywords.rds"))
t2 &lt;- Sys.time()
t2 - t1</code></pre>
</div>
<div id="submit-the-job-via-bsub" class="section level4">
<h4 class="hasAnchor">
<a href="#submit-the-job-via-bsub" class="anchor"></a>Submit the job via bsub</h4>
<p>It is recommened to use <code>-o</code> and <code>-e</code> to produce a output and error log for debugging if the job fails. The <code>.log</code> and <code>.err</code> will be just plain text file and saved in the same directory of where the submition occurs.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1"></a><span class="ex">bsub</span> -o consoleout.log \</span>
<span id="cb9-2"><a href="#cb9-2"></a>     -e consoleerr.err \</span>
<span id="cb9-3"><a href="#cb9-3"></a>     Rscript <span class="va">$workingDir</span>/recipe.R </span></code></pre></div>
</div>
<div id="retrieve-the-results" class="section level4">
<h4 class="hasAnchor">
<a href="#retrieve-the-results" class="anchor"></a>Retrieve the results</h4>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1"></a><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/library">library</a></span>(ggplot2)</span>
<span id="cb10-2"><a href="#cb10-2"></a>k &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/readRDS">readRDS</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/file.path">file.path</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/Sys.getenv">Sys.getenv</a></span>(<span class="st">"intermediateData"</span>), <span class="st">"keywords.rds"</span>))</span>
<span id="cb10-3"><a href="#cb10-3"></a><span class="kw">ggplot</span>(k, <span class="kw">aes</span>(keyword, freq)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_bar</span>(<span class="dt">stat =</span> <span class="st">"identity"</span>, <span class="dt">fill =</span> <span class="st">"cornflowerblue"</span>, </span>
<span id="cb10-4"><a href="#cb10-4"></a>    <span class="dt">colour =</span> <span class="st">"black"</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">"Most Frequently Occurring Words"</span>) <span class="op">+</span><span class="st"> </span><span class="kw">xlab</span>(<span class="st">"Keyword"</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb10-5"><a href="#cb10-5"></a><span class="st">    </span><span class="kw">ylab</span>(<span class="st">"Frequency"</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme_minimal</span>() <span class="op">+</span><span class="st"> </span><span class="kw">coord_flip</span>()</span></code></pre></div>
<p>For any questions or issues, please contact me at <a href="mailto:Blake.List@plantandfood.co.nz" class="email">Blake.List@plantandfood.co.nz</a>, or raise an issue at <a href="https://github.com/PlantandFoodResearch/PFRTextMiner" class="uri">https://github.com/PlantandFoodResearch/PFRTextMiner</a></p>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#scraping-files-from-an-iplant-webpage">Scraping files from an iPlant webpage</a></li>
      <li><a href="#mining-the-text-from-one-or-multiple-files">Mining the text from one or multiple files</a></li>
      <li><a href="#summarising-text-into-most-important-sentences">Summarising text into most important sentences</a></li>
      <li><a href="#extracting-the-most-frequent-keywords-from-the-text">Extracting the most frequent keywords from the text</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Blake List.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.3.0.</p>
</div>
      </footer>
</div>

  

  </body>
</html>
